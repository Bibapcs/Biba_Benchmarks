{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ab6515c-389c-48a0-9a57-c9ba612344d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cunmin/miniforge3/envs/ROCm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "An error occurred while trying to fetch ./anything-v5/unet: Error no file named diffusion_pytorch_model.safetensors found in directory ./anything-v5/unet.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "An error occurred while trying to fetch ./anything-v5/vae: Error no file named diffusion_pytorch_model.safetensors found in directory ./anything-v5/vae.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "/home/cunmin/miniforge3/envs/ROCm/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████| 6/6 [00:04<00:00,  1.41it/s]\n",
      "/home/cunmin/miniforge3/envs/ROCm/lib/python3.10/site-packages/diffusers/models/attention_processor.py:2383: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:517.)\n",
      "  hidden_states = F.scaled_dot_product_attention(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 15.98it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"./anything-v5\", #这里可以改成huggingface的model id，可以直接下载，或者其他本地的Diffusers模型目录，后面同理\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "\n",
    "image = pipe(prompt).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9edf02a-b007-44b4-8c7d-0a3388ead2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while trying to fetch ./anything-v5/unet: Error no file named diffusion_pytorch_model.safetensors found in directory ./anything-v5/unet.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "An error occurred while trying to fetch ./anything-v5/vae: Error no file named diffusion_pytorch_model.safetensors found in directory ./anything-v5/vae.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.08it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:03<00:00,  9.30it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "\n",
    "device = \"cuda\"\n",
    "model_id_or_path = \"./anything-v5\"\n",
    "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id_or_path, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg\"\n",
    "\n",
    "response = requests.get(url)\n",
    "init_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "init_image = init_image.resize((768, 512))\n",
    "\n",
    "prompt = \"A fantasy landscape, trending on artstation\"\n",
    "\n",
    "images = pipe(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f09a366-c93b-4451-be3d-fb9bb774d82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while trying to fetch ./anything-v5/unet: Error no file named diffusion_pytorch_model.safetensors found in directory ./anything-v5/unet.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "An error occurred while trying to fetch ./anything-v5/vae: Error no file named diffusion_pytorch_model.safetensors found in directory ./anything-v5/vae.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 50/50 [00:02<00:00, 19.21it/s]\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "import requests\n",
    "import torch\n",
    "from io import BytesIO\n",
    "\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "\n",
    "\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    return PIL.Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "\n",
    "img_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\n",
    "mask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n",
    "\n",
    "init_image = download_image(img_url).resize((512, 512))\n",
    "mask_image = download_image(mask_url).resize((512, 512))\n",
    "\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"./anything-v5\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"Face of a yellow cat, high resolution, sitting on a park bench\"\n",
    "image = pipe(prompt=prompt, image=init_image, mask_image=mask_image).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f760ac-5c7d-416d-bf8c-9eb497ab965c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cunmin/miniforge3/envs/ROCm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "An error occurred while trying to fetch ./stable-diffusion-x4-upscaler/vae: Error no file named diffusion_pytorch_model.safetensors found in directory ./stable-diffusion-x4-upscaler/vae.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "An error occurred while trying to fetch ./stable-diffusion-x4-upscaler/unet: Error no file named diffusion_pytorch_model.safetensors found in directory ./stable-diffusion-x4-upscaler/unet.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.28it/s]\n",
      "/home/cunmin/miniforge3/envs/ROCm/lib/python3.10/site-packages/diffusers/models/attention_processor.py:2383: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:517.)\n",
      "  hidden_states = F.scaled_dot_product_attention(\n",
      " 64%|█████████████████████████████████████████████████████                              | 48/75 [00:02<00:01, 19.35it/s]"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from diffusers import StableDiffusionUpscalePipeline\n",
    "import torch\n",
    "\n",
    "# load model and scheduler\n",
    "model_id = \"./stable-diffusion-x4-upscaler\"\n",
    "pipeline = StableDiffusionUpscalePipeline.from_pretrained(\n",
    "    model_id, torch_dtype=torch.float16\n",
    ")\n",
    "pipeline = pipeline.to(\"cuda\")\n",
    "\n",
    "# let's download an  image\n",
    "url = \"https://hf-mirror.com/datasets/hf-internal-testing/diffusers-images/resolve/main/sd2-upscale/low_res_cat.png\"\n",
    "response = requests.get(url)\n",
    "low_res_img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "low_res_img = low_res_img.resize((128, 128))\n",
    "prompt = \"a white cat\"\n",
    "\n",
    "upscaled_image = pipeline(prompt=prompt, image=low_res_img).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753c9c2-4767-4324-8339-4e9bdb93ba74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
